**Бэкенд проекта Speech Performance Analyzer**

*REST API на FastAPI для анализа речи с использованием современных ML-моделей*

**Основные модули**

- main.py — точка входа, эндпоинт POST /analyze, обработка загрузки, конвертация через FFmpeg, координация pipeline

- transcription.py — распознавание речи и диаризация через WhisperX и pyannote.audio

- emotions.py — анализ эмоциональной окраски на основе WavLM и MLP

- llm_service.py — генерация текстового отчёта через локальную LLM qwen2.5:3b в Ollama с валидацией через Pydantic

**Pipeline обработки**

1. Сохранение входного файла во временную директорию temp
2. Обрезка и конвертация в WAV 16 кГц моно через FFmpeg
3. Транскрибация и разделение по спикерам (WhisperX + pyannote)
4. Извлечение эмоций для каждого сегмента (WavLM → эмбеддинги, MLP → классификация)
5. Формирование подробного промпта и генерация отчёта через Ollama
6. Возврат JSON с транскрибацией, данными для графика и структурированным отчётом

**Требования к окружению**

- Python 3.9 или выше
- FFmpeg, добавленный в системную переменную PATH
- Ollama, запущенная в фоне, с моделью qwen2.5:3b
- Файл models/best_model.pth с весами MLP (должен находиться в папке models)
Токен Hugging Face для pyannote.audio (указать в transcription.py)

**Запуск**
1. Перейти в папку backend
2. Выполнить
python main.py
3. Сервер запустится на http://0.0.0.0:8000


*Дополнительно*

- Все модели выгружаются из памяти после использования
- В случае ошибки — аварийная очистка CUDA и возврат HTTP 500
- Для демонстрации можно использовать заглушки (заменить тело функций на возврат mock-данных)