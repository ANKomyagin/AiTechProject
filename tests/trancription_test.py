"""
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã –º–æ–¥—É–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏, –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
"""

import torch
import whisperx
import json
import os

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚úÖ PyTorch device: {device}")
if device == "cuda":
    gpu_name = torch.cuda.get_device_name(0)
    vram = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f"üöÄ GPU: {gpu_name} ({vram:.1f} GB VRAM)")
else:
    print("‚ö†Ô∏è GPU –Ω–µ –Ω–∞–π–¥–µ–Ω. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å—Å—è –Ω–∞ CPU (–º–µ–¥–ª–µ–Ω–Ω–æ).")

# 2. –£–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (–º–æ–∂–Ω–æ .m4a, .mp3, .wav –∏ —Ç.–¥.)
audio_path = "audio.m4a"

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
if not os.path.exists(audio_path):
    raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")

# 3. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å WhisperX
model = whisperx.load_model("medium", device=device)

# 4. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
print("üéß –ù–∞—á–∏–Ω–∞—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é...")
result = model.transcribe(audio_path)

# 5. –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
text = "\n".join([seg["text"].strip() for seg in result["segments"] if seg["text"].strip()])

# 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ txt
output_path = "transcript.txt"
with open(output_path, "w", encoding="utf-8") as f:
    f.write(text)

print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_path}")

# 7. (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) –í—ã–≤–æ–¥ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ –≤ –∫–æ–Ω—Å–æ–ª—å
print("\nüìù –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
print("\n".join(text.splitlines()[:10]))
